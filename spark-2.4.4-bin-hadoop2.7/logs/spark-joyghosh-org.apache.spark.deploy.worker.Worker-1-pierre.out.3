Spark Command: /usr/local/jdk1.8.0_51/bin/java -cp /s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/conf/:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/jars/*:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/hadoop-conf/ -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://santa-fe.cs.colostate.edu:47002
========================================
2019-11-20 14:26:45,079 INFO worker.Worker: Started daemon with process name: 23821@pierre
2019-11-20 14:26:45,090 INFO util.SignalUtils: Registered signal handler for TERM
2019-11-20 14:26:45,090 INFO util.SignalUtils: Registered signal handler for HUP
2019-11-20 14:26:45,090 INFO util.SignalUtils: Registered signal handler for INT
2019-11-20 14:26:45,611 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-11-20 14:26:45,770 INFO spark.SecurityManager: Changing view acls to: joyghosh
2019-11-20 14:26:45,771 INFO spark.SecurityManager: Changing modify acls to: joyghosh
2019-11-20 14:26:45,771 INFO spark.SecurityManager: Changing view acls groups to: 
2019-11-20 14:26:45,772 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-11-20 14:26:45,772 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(joyghosh); groups with view permissions: Set(); users  with modify permissions: Set(joyghosh); groups with modify permissions: Set()
2019-11-20 14:26:46,269 INFO util.Utils: Successfully started service 'sparkWorker' on port 33907.
2019-11-20 14:26:46,507 INFO worker.Worker: Starting Spark worker 129.82.44.163:33907 with 1 cores, 2.0 GB RAM
2019-11-20 14:26:46,510 INFO worker.Worker: Running Spark version 2.4.4
2019-11-20 14:26:46,510 INFO worker.Worker: Spark home: /s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7
2019-11-20 14:26:46,561 INFO util.log: Logging initialized @3602ms
2019-11-20 14:26:46,609 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-20 14:26:46,626 INFO server.Server: Started @3669ms
2019-11-20 14:26:46,643 WARN util.Utils: Service 'WorkerUI' could not bind on port 8081. Attempting port 8082.
2019-11-20 14:26:46,643 WARN util.Utils: Service 'WorkerUI' could not bind on port 8082. Attempting port 8083.
2019-11-20 14:26:46,644 WARN util.Utils: Service 'WorkerUI' could not bind on port 8083. Attempting port 8084.
2019-11-20 14:26:46,644 WARN util.Utils: Service 'WorkerUI' could not bind on port 8084. Attempting port 8085.
2019-11-20 14:26:46,649 INFO server.AbstractConnector: Started ServerConnector@1ebaf93{HTTP/1.1,[http/1.1]}{0.0.0.0:8085}
2019-11-20 14:26:46,650 INFO util.Utils: Successfully started service 'WorkerUI' on port 8085.
2019-11-20 14:26:46,675 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7e7f71{/logPage,null,AVAILABLE,@Spark}
2019-11-20 14:26:46,676 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d98322{/logPage/json,null,AVAILABLE,@Spark}
2019-11-20 14:26:46,676 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5c1321{/,null,AVAILABLE,@Spark}
2019-11-20 14:26:46,677 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@13bf66e{/json,null,AVAILABLE,@Spark}
2019-11-20 14:26:46,690 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@187b8b8{/static,null,AVAILABLE,@Spark}
2019-11-20 14:26:46,691 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@af6bfa{/log,null,AVAILABLE,@Spark}
2019-11-20 14:26:46,693 INFO ui.WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://pierre.cs.colostate.edu:8085
2019-11-20 14:26:46,695 INFO worker.Worker: Connecting to master santa-fe.cs.colostate.edu:47002...
2019-11-20 14:26:46,719 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@11a3d36{/metrics/json,null,AVAILABLE,@Spark}
2019-11-20 14:26:46,777 INFO client.TransportClientFactory: Successfully created connection to santa-fe.cs.colostate.edu/129.82.44.171:47002 after 59 ms (0 ms spent in bootstraps)
2019-11-20 14:26:46,952 INFO worker.Worker: Successfully registered with master spark://santa-fe.cs.colostate.edu:47002
2019-11-20 14:27:20,161 INFO worker.Worker: Asked to launch executor app-20191120142719-0000/6 for PythonPageRank
2019-11-20 14:27:20,186 INFO spark.SecurityManager: Changing view acls to: joyghosh
2019-11-20 14:27:20,186 INFO spark.SecurityManager: Changing modify acls to: joyghosh
2019-11-20 14:27:20,186 INFO spark.SecurityManager: Changing view acls groups to: 
2019-11-20 14:27:20,186 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-11-20 14:27:20,186 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(joyghosh); groups with view permissions: Set(); users  with modify permissions: Set(joyghosh); groups with modify permissions: Set()
2019-11-20 14:27:20,242 INFO worker.ExecutorRunner: Launch command: "/usr/local/jdk1.8.0_51/bin/java" "-cp" "/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/conf/:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/jars/*:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/hadoop-conf/" "-Xmx1024M" "-Dspark.driver.port=41619" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@santa-fe.cs.colostate.edu:41619" "--executor-id" "6" "--hostname" "129.82.44.163" "--cores" "1" "--app-id" "app-20191120142719-0000" "--worker-url" "spark://Worker@129.82.44.163:33907"
2019-11-20 14:27:22,167 INFO worker.Worker: Asked to kill executor app-20191120142719-0000/6
2019-11-20 14:27:22,168 INFO worker.ExecutorRunner: Runner thread for executor app-20191120142719-0000/6 interrupted
2019-11-20 14:27:22,168 INFO worker.ExecutorRunner: Killing process!
2019-11-20 14:27:22,197 INFO worker.Worker: Executor app-20191120142719-0000/6 finished with state KILLED exitStatus 143
2019-11-20 14:27:22,197 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 6
2019-11-20 14:27:22,198 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20191120142719-0000, execId=6)
2019-11-20 14:27:22,202 INFO worker.Worker: Cleaning up local directories for application app-20191120142719-0000
2019-11-20 14:27:22,202 INFO shuffle.ExternalShuffleBlockResolver: Application app-20191120142719-0000 removed, cleanupLocalDirs = true
2019-11-20 14:28:11,677 INFO worker.Worker: Asked to launch executor app-20191120142811-0001/6 for PythonPageRank
2019-11-20 14:28:11,680 INFO spark.SecurityManager: Changing view acls to: joyghosh
2019-11-20 14:28:11,680 INFO spark.SecurityManager: Changing modify acls to: joyghosh
2019-11-20 14:28:11,680 INFO spark.SecurityManager: Changing view acls groups to: 
2019-11-20 14:28:11,680 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-11-20 14:28:11,680 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(joyghosh); groups with view permissions: Set(); users  with modify permissions: Set(joyghosh); groups with modify permissions: Set()
2019-11-20 14:28:11,726 INFO worker.ExecutorRunner: Launch command: "/usr/local/jdk1.8.0_51/bin/java" "-cp" "/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/conf/:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/jars/*:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/hadoop-conf/" "-Xmx1024M" "-Dspark.driver.port=32983" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@santa-fe.cs.colostate.edu:32983" "--executor-id" "6" "--hostname" "129.82.44.163" "--cores" "1" "--app-id" "app-20191120142811-0001" "--worker-url" "spark://Worker@129.82.44.163:33907"
2019-11-20 14:28:13,660 INFO worker.Worker: Asked to kill executor app-20191120142811-0001/6
2019-11-20 14:28:13,660 INFO worker.ExecutorRunner: Runner thread for executor app-20191120142811-0001/6 interrupted
2019-11-20 14:28:13,660 INFO worker.ExecutorRunner: Killing process!
2019-11-20 14:28:13,674 INFO worker.Worker: Executor app-20191120142811-0001/6 finished with state KILLED exitStatus 143
2019-11-20 14:28:13,674 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 6
2019-11-20 14:28:13,674 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20191120142811-0001, execId=6)
2019-11-20 14:28:13,674 INFO shuffle.ExternalShuffleBlockResolver: Application app-20191120142811-0001 removed, cleanupLocalDirs = true
2019-11-20 14:28:13,674 INFO worker.Worker: Cleaning up local directories for application app-20191120142811-0001
2019-11-20 14:29:50,217 INFO worker.Worker: Asked to launch executor app-20191120142950-0002/6 for PythonPageRank
2019-11-20 14:29:50,224 INFO spark.SecurityManager: Changing view acls to: joyghosh
2019-11-20 14:29:50,224 INFO spark.SecurityManager: Changing modify acls to: joyghosh
2019-11-20 14:29:50,224 INFO spark.SecurityManager: Changing view acls groups to: 
2019-11-20 14:29:50,224 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-11-20 14:29:50,225 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(joyghosh); groups with view permissions: Set(); users  with modify permissions: Set(joyghosh); groups with modify permissions: Set()
2019-11-20 14:29:50,281 INFO worker.ExecutorRunner: Launch command: "/usr/local/jdk1.8.0_51/bin/java" "-cp" "/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/conf/:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/jars/*:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/hadoop-conf/" "-Xmx1024M" "-Dspark.driver.port=38555" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@santa-fe.cs.colostate.edu:38555" "--executor-id" "6" "--hostname" "129.82.44.163" "--cores" "1" "--app-id" "app-20191120142950-0002" "--worker-url" "spark://Worker@129.82.44.163:33907"
2019-11-20 14:30:23,031 INFO worker.Worker: Asked to kill executor app-20191120142950-0002/6
2019-11-20 14:30:23,032 INFO worker.ExecutorRunner: Runner thread for executor app-20191120142950-0002/6 interrupted
2019-11-20 14:30:23,033 INFO worker.ExecutorRunner: Killing process!
2019-11-20 14:30:23,132 INFO worker.Worker: Executor app-20191120142950-0002/6 finished with state KILLED exitStatus 143
2019-11-20 14:30:23,133 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 6
2019-11-20 14:30:23,133 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20191120142950-0002, execId=6)
2019-11-20 14:30:23,133 INFO shuffle.ExternalShuffleBlockResolver: Application app-20191120142950-0002 removed, cleanupLocalDirs = true
2019-11-20 14:30:23,133 INFO worker.Worker: Cleaning up local directories for application app-20191120142950-0002
2019-11-20 15:03:53,764 ERROR worker.Worker: RECEIVED SIGNAL TERM
2019-11-20 15:03:53,767 INFO util.ShutdownHookManager: Shutdown hook called
2019-11-20 15:03:53,768 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-c4aa47a3-cfa7-4dcd-b558-835f56b9b1ab
