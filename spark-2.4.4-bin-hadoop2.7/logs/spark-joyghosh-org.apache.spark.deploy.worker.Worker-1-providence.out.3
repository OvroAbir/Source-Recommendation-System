Spark Command: /usr/local/jdk1.8.0_51/bin/java -cp /s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/conf/:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/jars/*:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/hadoop-conf/ -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://santa-fe.cs.colostate.edu:47002
========================================
2019-11-20 14:26:55,842 INFO worker.Worker: Started daemon with process name: 5988@providence
2019-11-20 14:26:55,851 INFO util.SignalUtils: Registered signal handler for TERM
2019-11-20 14:26:55,851 INFO util.SignalUtils: Registered signal handler for HUP
2019-11-20 14:26:55,851 INFO util.SignalUtils: Registered signal handler for INT
2019-11-20 14:26:56,366 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-11-20 14:26:56,489 INFO spark.SecurityManager: Changing view acls to: joyghosh
2019-11-20 14:26:56,489 INFO spark.SecurityManager: Changing modify acls to: joyghosh
2019-11-20 14:26:56,490 INFO spark.SecurityManager: Changing view acls groups to: 
2019-11-20 14:26:56,491 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-11-20 14:26:56,493 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(joyghosh); groups with view permissions: Set(); users  with modify permissions: Set(joyghosh); groups with modify permissions: Set()
2019-11-20 14:26:56,904 INFO util.Utils: Successfully started service 'sparkWorker' on port 44359.
2019-11-20 14:26:57,138 INFO worker.Worker: Starting Spark worker 129.82.44.164:44359 with 1 cores, 2.0 GB RAM
2019-11-20 14:26:57,142 INFO worker.Worker: Running Spark version 2.4.4
2019-11-20 14:26:57,142 INFO worker.Worker: Spark home: /s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7
2019-11-20 14:26:57,195 INFO util.log: Logging initialized @2828ms
2019-11-20 14:26:57,247 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-20 14:26:57,263 INFO server.Server: Started @2898ms
2019-11-20 14:26:57,279 WARN util.Utils: Service 'WorkerUI' could not bind on port 8081. Attempting port 8082.
2019-11-20 14:26:57,279 WARN util.Utils: Service 'WorkerUI' could not bind on port 8082. Attempting port 8083.
2019-11-20 14:26:57,279 WARN util.Utils: Service 'WorkerUI' could not bind on port 8083. Attempting port 8084.
2019-11-20 14:26:57,280 WARN util.Utils: Service 'WorkerUI' could not bind on port 8084. Attempting port 8085.
2019-11-20 14:26:57,286 INFO server.AbstractConnector: Started ServerConnector@1751567{HTTP/1.1,[http/1.1]}{0.0.0.0:8085}
2019-11-20 14:26:57,286 INFO util.Utils: Successfully started service 'WorkerUI' on port 8085.
2019-11-20 14:26:57,311 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1e6300e{/logPage,null,AVAILABLE,@Spark}
2019-11-20 14:26:57,311 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@82d97e{/logPage/json,null,AVAILABLE,@Spark}
2019-11-20 14:26:57,312 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@c8438f{/,null,AVAILABLE,@Spark}
2019-11-20 14:26:57,313 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@11ec7f5{/json,null,AVAILABLE,@Spark}
2019-11-20 14:26:57,326 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@17fa4c1{/static,null,AVAILABLE,@Spark}
2019-11-20 14:26:57,327 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@e0eff2{/log,null,AVAILABLE,@Spark}
2019-11-20 14:26:57,329 INFO ui.WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://providence.cs.colostate.edu:8085
2019-11-20 14:26:57,333 INFO worker.Worker: Connecting to master santa-fe.cs.colostate.edu:47002...
2019-11-20 14:26:57,360 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@f7b79e{/metrics/json,null,AVAILABLE,@Spark}
2019-11-20 14:26:57,431 INFO client.TransportClientFactory: Successfully created connection to santa-fe.cs.colostate.edu/129.82.44.171:47002 after 68 ms (0 ms spent in bootstraps)
2019-11-20 14:26:57,510 INFO worker.Worker: Successfully registered with master spark://santa-fe.cs.colostate.edu:47002
2019-11-20 14:27:20,150 INFO worker.Worker: Asked to launch executor app-20191120142719-0000/3 for PythonPageRank
2019-11-20 14:27:20,180 INFO spark.SecurityManager: Changing view acls to: joyghosh
2019-11-20 14:27:20,180 INFO spark.SecurityManager: Changing modify acls to: joyghosh
2019-11-20 14:27:20,180 INFO spark.SecurityManager: Changing view acls groups to: 
2019-11-20 14:27:20,180 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-11-20 14:27:20,180 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(joyghosh); groups with view permissions: Set(); users  with modify permissions: Set(joyghosh); groups with modify permissions: Set()
2019-11-20 14:27:20,235 INFO worker.ExecutorRunner: Launch command: "/usr/local/jdk1.8.0_51/bin/java" "-cp" "/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/conf/:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/jars/*:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/hadoop-conf/" "-Xmx1024M" "-Dspark.driver.port=41619" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@santa-fe.cs.colostate.edu:41619" "--executor-id" "3" "--hostname" "129.82.44.164" "--cores" "1" "--app-id" "app-20191120142719-0000" "--worker-url" "spark://Worker@129.82.44.164:44359"
2019-11-20 14:27:22,165 INFO worker.Worker: Asked to kill executor app-20191120142719-0000/3
2019-11-20 14:27:22,168 INFO worker.ExecutorRunner: Runner thread for executor app-20191120142719-0000/3 interrupted
2019-11-20 14:27:22,173 INFO worker.ExecutorRunner: Killing process!
2019-11-20 14:27:22,216 INFO worker.Worker: Executor app-20191120142719-0000/3 finished with state KILLED exitStatus 143
2019-11-20 14:27:22,216 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 3
2019-11-20 14:27:22,217 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20191120142719-0000, execId=3)
2019-11-20 14:27:22,220 INFO shuffle.ExternalShuffleBlockResolver: Application app-20191120142719-0000 removed, cleanupLocalDirs = true
2019-11-20 14:27:22,220 INFO worker.Worker: Cleaning up local directories for application app-20191120142719-0000
2019-11-20 14:28:11,658 INFO worker.Worker: Asked to launch executor app-20191120142811-0001/3 for PythonPageRank
2019-11-20 14:28:11,668 INFO spark.SecurityManager: Changing view acls to: joyghosh
2019-11-20 14:28:11,668 INFO spark.SecurityManager: Changing modify acls to: joyghosh
2019-11-20 14:28:11,668 INFO spark.SecurityManager: Changing view acls groups to: 
2019-11-20 14:28:11,668 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-11-20 14:28:11,668 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(joyghosh); groups with view permissions: Set(); users  with modify permissions: Set(joyghosh); groups with modify permissions: Set()
2019-11-20 14:28:11,740 INFO worker.ExecutorRunner: Launch command: "/usr/local/jdk1.8.0_51/bin/java" "-cp" "/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/conf/:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/jars/*:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/hadoop-conf/" "-Xmx1024M" "-Dspark.driver.port=32983" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@santa-fe.cs.colostate.edu:32983" "--executor-id" "3" "--hostname" "129.82.44.164" "--cores" "1" "--app-id" "app-20191120142811-0001" "--worker-url" "spark://Worker@129.82.44.164:44359"
2019-11-20 14:28:13,658 INFO worker.Worker: Asked to kill executor app-20191120142811-0001/3
2019-11-20 14:28:13,658 INFO worker.ExecutorRunner: Runner thread for executor app-20191120142811-0001/3 interrupted
2019-11-20 14:28:13,659 INFO worker.ExecutorRunner: Killing process!
2019-11-20 14:28:13,681 INFO worker.Worker: Executor app-20191120142811-0001/3 finished with state KILLED exitStatus 143
2019-11-20 14:28:13,681 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 3
2019-11-20 14:28:13,681 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20191120142811-0001, execId=3)
2019-11-20 14:28:13,681 INFO shuffle.ExternalShuffleBlockResolver: Application app-20191120142811-0001 removed, cleanupLocalDirs = true
2019-11-20 14:28:13,681 INFO worker.Worker: Cleaning up local directories for application app-20191120142811-0001
2019-11-20 14:29:50,214 INFO worker.Worker: Asked to launch executor app-20191120142950-0002/3 for PythonPageRank
2019-11-20 14:29:50,221 INFO spark.SecurityManager: Changing view acls to: joyghosh
2019-11-20 14:29:50,221 INFO spark.SecurityManager: Changing modify acls to: joyghosh
2019-11-20 14:29:50,221 INFO spark.SecurityManager: Changing view acls groups to: 
2019-11-20 14:29:50,221 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-11-20 14:29:50,221 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(joyghosh); groups with view permissions: Set(); users  with modify permissions: Set(joyghosh); groups with modify permissions: Set()
2019-11-20 14:29:50,280 INFO worker.ExecutorRunner: Launch command: "/usr/local/jdk1.8.0_51/bin/java" "-cp" "/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/conf/:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/jars/*:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/hadoop-conf/" "-Xmx1024M" "-Dspark.driver.port=38555" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@santa-fe.cs.colostate.edu:38555" "--executor-id" "3" "--hostname" "129.82.44.164" "--cores" "1" "--app-id" "app-20191120142950-0002" "--worker-url" "spark://Worker@129.82.44.164:44359"
2019-11-20 14:30:23,029 INFO worker.Worker: Asked to kill executor app-20191120142950-0002/3
2019-11-20 14:30:23,030 INFO worker.ExecutorRunner: Runner thread for executor app-20191120142950-0002/3 interrupted
2019-11-20 14:30:23,030 INFO worker.ExecutorRunner: Killing process!
2019-11-20 14:30:23,134 INFO worker.Worker: Executor app-20191120142950-0002/3 finished with state KILLED exitStatus 143
2019-11-20 14:30:23,134 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 3
2019-11-20 14:30:23,134 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20191120142950-0002, execId=3)
2019-11-20 14:30:23,134 INFO shuffle.ExternalShuffleBlockResolver: Application app-20191120142950-0002 removed, cleanupLocalDirs = true
2019-11-20 14:30:23,134 INFO worker.Worker: Cleaning up local directories for application app-20191120142950-0002
2019-11-20 15:03:53,760 ERROR worker.Worker: RECEIVED SIGNAL TERM
2019-11-20 15:03:53,763 INFO util.ShutdownHookManager: Shutdown hook called
2019-11-20 15:03:53,764 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-62b8c819-b806-44c7-b45d-03aa1093aff0
