Spark Command: /usr/local/jdk1.8.0_51/bin/java -cp /s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/conf/:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/jars/*:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/hadoop-conf/ -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8082 spark://santa-fe.cs.colostate.edu:47002
========================================
2019-11-20 14:26:48,518 INFO worker.Worker: Started daemon with process name: 23919@pierre
2019-11-20 14:26:48,526 INFO util.SignalUtils: Registered signal handler for TERM
2019-11-20 14:26:48,526 INFO util.SignalUtils: Registered signal handler for HUP
2019-11-20 14:26:48,526 INFO util.SignalUtils: Registered signal handler for INT
2019-11-20 14:26:49,022 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-11-20 14:26:49,155 INFO spark.SecurityManager: Changing view acls to: joyghosh
2019-11-20 14:26:49,155 INFO spark.SecurityManager: Changing modify acls to: joyghosh
2019-11-20 14:26:49,156 INFO spark.SecurityManager: Changing view acls groups to: 
2019-11-20 14:26:49,156 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-11-20 14:26:49,157 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(joyghosh); groups with view permissions: Set(); users  with modify permissions: Set(joyghosh); groups with modify permissions: Set()
2019-11-20 14:26:49,606 INFO util.Utils: Successfully started service 'sparkWorker' on port 40225.
2019-11-20 14:26:49,842 INFO worker.Worker: Starting Spark worker 129.82.44.163:40225 with 1 cores, 2.0 GB RAM
2019-11-20 14:26:49,845 INFO worker.Worker: Running Spark version 2.4.4
2019-11-20 14:26:49,845 INFO worker.Worker: Spark home: /s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7
2019-11-20 14:26:49,892 INFO util.log: Logging initialized @3307ms
2019-11-20 14:26:49,939 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-20 14:26:49,955 INFO server.Server: Started @3372ms
2019-11-20 14:26:49,969 WARN util.Utils: Service 'WorkerUI' could not bind on port 8082. Attempting port 8083.
2019-11-20 14:26:49,970 WARN util.Utils: Service 'WorkerUI' could not bind on port 8083. Attempting port 8084.
2019-11-20 14:26:49,970 WARN util.Utils: Service 'WorkerUI' could not bind on port 8084. Attempting port 8085.
2019-11-20 14:26:49,971 WARN util.Utils: Service 'WorkerUI' could not bind on port 8085. Attempting port 8086.
2019-11-20 14:26:49,976 INFO server.AbstractConnector: Started ServerConnector@17575b7{HTTP/1.1,[http/1.1]}{0.0.0.0:8086}
2019-11-20 14:26:49,976 INFO util.Utils: Successfully started service 'WorkerUI' on port 8086.
2019-11-20 14:26:50,001 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@f5d20a{/logPage,null,AVAILABLE,@Spark}
2019-11-20 14:26:50,002 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1931ae9{/logPage/json,null,AVAILABLE,@Spark}
2019-11-20 14:26:50,003 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5726d0{/,null,AVAILABLE,@Spark}
2019-11-20 14:26:50,004 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@16f1568{/json,null,AVAILABLE,@Spark}
2019-11-20 14:26:50,017 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@a606be{/static,null,AVAILABLE,@Spark}
2019-11-20 14:26:50,017 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1285dc1{/log,null,AVAILABLE,@Spark}
2019-11-20 14:26:50,019 INFO ui.WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://pierre.cs.colostate.edu:8086
2019-11-20 14:26:50,022 INFO worker.Worker: Connecting to master santa-fe.cs.colostate.edu:47002...
2019-11-20 14:26:50,043 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@f0fbc5{/metrics/json,null,AVAILABLE,@Spark}
2019-11-20 14:26:50,112 INFO client.TransportClientFactory: Successfully created connection to santa-fe.cs.colostate.edu/129.82.44.171:47002 after 61 ms (0 ms spent in bootstraps)
2019-11-20 14:26:50,186 INFO worker.Worker: Successfully registered with master spark://santa-fe.cs.colostate.edu:47002
2019-11-20 14:27:20,157 INFO worker.Worker: Asked to launch executor app-20191120142719-0000/10 for PythonPageRank
2019-11-20 14:27:20,185 INFO spark.SecurityManager: Changing view acls to: joyghosh
2019-11-20 14:27:20,186 INFO spark.SecurityManager: Changing modify acls to: joyghosh
2019-11-20 14:27:20,186 INFO spark.SecurityManager: Changing view acls groups to: 
2019-11-20 14:27:20,186 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-11-20 14:27:20,186 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(joyghosh); groups with view permissions: Set(); users  with modify permissions: Set(joyghosh); groups with modify permissions: Set()
2019-11-20 14:27:20,241 INFO worker.ExecutorRunner: Launch command: "/usr/local/jdk1.8.0_51/bin/java" "-cp" "/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/conf/:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/jars/*:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/hadoop-conf/" "-Xmx1024M" "-Dspark.driver.port=41619" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@santa-fe.cs.colostate.edu:41619" "--executor-id" "10" "--hostname" "129.82.44.163" "--cores" "1" "--app-id" "app-20191120142719-0000" "--worker-url" "spark://Worker@129.82.44.163:40225"
2019-11-20 14:27:22,167 INFO worker.Worker: Asked to kill executor app-20191120142719-0000/10
2019-11-20 14:27:22,168 INFO worker.ExecutorRunner: Runner thread for executor app-20191120142719-0000/10 interrupted
2019-11-20 14:27:22,168 INFO worker.ExecutorRunner: Killing process!
2019-11-20 14:27:22,196 INFO worker.Worker: Executor app-20191120142719-0000/10 finished with state KILLED exitStatus 143
2019-11-20 14:27:22,197 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 10
2019-11-20 14:27:22,198 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20191120142719-0000, execId=10)
2019-11-20 14:27:22,200 INFO shuffle.ExternalShuffleBlockResolver: Application app-20191120142719-0000 removed, cleanupLocalDirs = true
2019-11-20 14:27:22,200 INFO worker.Worker: Cleaning up local directories for application app-20191120142719-0000
2019-11-20 14:28:11,663 INFO worker.Worker: Asked to launch executor app-20191120142811-0001/10 for PythonPageRank
2019-11-20 14:28:11,672 INFO spark.SecurityManager: Changing view acls to: joyghosh
2019-11-20 14:28:11,672 INFO spark.SecurityManager: Changing modify acls to: joyghosh
2019-11-20 14:28:11,672 INFO spark.SecurityManager: Changing view acls groups to: 
2019-11-20 14:28:11,672 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-11-20 14:28:11,673 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(joyghosh); groups with view permissions: Set(); users  with modify permissions: Set(joyghosh); groups with modify permissions: Set()
2019-11-20 14:28:11,726 INFO worker.ExecutorRunner: Launch command: "/usr/local/jdk1.8.0_51/bin/java" "-cp" "/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/conf/:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/jars/*:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/hadoop-conf/" "-Xmx1024M" "-Dspark.driver.port=32983" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@santa-fe.cs.colostate.edu:32983" "--executor-id" "10" "--hostname" "129.82.44.163" "--cores" "1" "--app-id" "app-20191120142811-0001" "--worker-url" "spark://Worker@129.82.44.163:40225"
2019-11-20 14:28:13,663 INFO worker.Worker: Asked to kill executor app-20191120142811-0001/10
2019-11-20 14:28:13,663 INFO worker.ExecutorRunner: Runner thread for executor app-20191120142811-0001/10 interrupted
2019-11-20 14:28:13,663 INFO worker.ExecutorRunner: Killing process!
2019-11-20 14:28:13,677 INFO worker.Worker: Executor app-20191120142811-0001/10 finished with state KILLED exitStatus 143
2019-11-20 14:28:13,677 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 10
2019-11-20 14:28:13,677 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20191120142811-0001, execId=10)
2019-11-20 14:28:13,677 INFO shuffle.ExternalShuffleBlockResolver: Application app-20191120142811-0001 removed, cleanupLocalDirs = true
2019-11-20 14:28:13,677 INFO worker.Worker: Cleaning up local directories for application app-20191120142811-0001
2019-11-20 14:29:50,218 INFO worker.Worker: Asked to launch executor app-20191120142950-0002/10 for PythonPageRank
2019-11-20 14:29:50,225 INFO spark.SecurityManager: Changing view acls to: joyghosh
2019-11-20 14:29:50,225 INFO spark.SecurityManager: Changing modify acls to: joyghosh
2019-11-20 14:29:50,225 INFO spark.SecurityManager: Changing view acls groups to: 
2019-11-20 14:29:50,225 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-11-20 14:29:50,225 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(joyghosh); groups with view permissions: Set(); users  with modify permissions: Set(joyghosh); groups with modify permissions: Set()
2019-11-20 14:29:50,281 INFO worker.ExecutorRunner: Launch command: "/usr/local/jdk1.8.0_51/bin/java" "-cp" "/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/conf/:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/spark-2.4.4-bin-hadoop2.7/jars/*:/s/chopin/a/grad/joyghosh/Source-Recommendation-System/hadoop-conf/" "-Xmx1024M" "-Dspark.driver.port=38555" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@santa-fe.cs.colostate.edu:38555" "--executor-id" "10" "--hostname" "129.82.44.163" "--cores" "1" "--app-id" "app-20191120142950-0002" "--worker-url" "spark://Worker@129.82.44.163:40225"
2019-11-20 14:30:23,031 INFO worker.Worker: Asked to kill executor app-20191120142950-0002/10
2019-11-20 14:30:23,031 INFO worker.ExecutorRunner: Runner thread for executor app-20191120142950-0002/10 interrupted
2019-11-20 14:30:23,032 INFO worker.ExecutorRunner: Killing process!
2019-11-20 14:30:23,132 INFO worker.Worker: Executor app-20191120142950-0002/10 finished with state KILLED exitStatus 143
2019-11-20 14:30:23,133 INFO shuffle.ExternalShuffleBlockResolver: Clean up non-shuffle files associated with the finished executor 10
2019-11-20 14:30:23,133 INFO shuffle.ExternalShuffleBlockResolver: Executor is not registered (appId=app-20191120142950-0002, execId=10)
2019-11-20 14:30:23,133 INFO shuffle.ExternalShuffleBlockResolver: Application app-20191120142950-0002 removed, cleanupLocalDirs = true
2019-11-20 14:30:23,133 INFO worker.Worker: Cleaning up local directories for application app-20191120142950-0002
2019-11-20 15:03:53,795 ERROR worker.Worker: RECEIVED SIGNAL TERM
2019-11-20 15:03:53,799 INFO util.ShutdownHookManager: Shutdown hook called
2019-11-20 15:03:53,800 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-90a49dc3-6b0c-4a1c-9d79-417f615e183f
